{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from project_utils import runModel, split_and_scale\n",
    "from sklearn import feature_selection\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.base import ClassifierMixin\n",
    "from numpy import ndarray\n",
    "import time\n",
    "from project_utils import runModel, runModelCV, training_with_PCA, scaling, runModelStepwiseSelection\n",
    "from scipy.stats import uniform\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, RandomizedSearchCV\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set data for binary classification\n",
    "\n",
    "df = pd.read_csv('npf_train.csv')\n",
    "df = df.drop(columns=['date', 'id', 'partlybad'])\n",
    "df['class2'] = (df['class4'] == 'nonevent').astype(int)\n",
    "X = df.drop(columns=['class4', 'class2'])\n",
    "#X = X[[\"CO2168.mean\", \"CO242.mean\", \"CO2504.mean\"]]\n",
    "y = df['class2']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define your model parametrs here and add them to the list\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=50, random_state=42, class_weight={1: 0.55, 0:0.45}, min_samples_leaf=5, min_samples_split=5)\n",
    "lr = LogisticRegressionCV(max_iter=10)\n",
    "nb = GaussianNB()\n",
    "svm = SVC(probability=True)\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "#xcols = xdf.columns\n",
    "\n",
    "models = [rf, lr, nb, svm, knn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kukkojoo/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(class_weight={0: 0.45, 1: 0.55}, min_samples_leaf=5,\n",
      "                       min_samples_split=5, n_estimators=50, random_state=42) 588.185201883316\n",
      "LogisticRegressionCV(max_iter=10) 854.709951877594\n",
      "GaussianNB() 17.87069010734558\n",
      "SVC(probability=True) 168.50346302986145\n",
      "KNeighborsClassifier() 34.33825492858887\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for m in models:\n",
    "    results.append(runModelStepwiseSelection(m, X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitAndScaleDate(X, y, split=0.33):\n",
    "    scaler = StandardScaler()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split)\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.fit_transform(X_test)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runModel(m, X_, y_):\n",
    "    time_start = time.time()\n",
    "    classifier_pipeline = make_pipeline(StandardScaler(), m)\n",
    "    \n",
    "    cv = KFold(n_splits=10, random_state=0, shuffle=False)\n",
    "    \n",
    "    sfs1 = SFS(classifier_pipeline, \n",
    "        k_features=(1, 100), \n",
    "        forward=True, \n",
    "        scoring='accuracy',\n",
    "        cv=cv,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    sfs1.fit(X_,y_)\n",
    "    time_end = time.time()\n",
    "    time_run = time_end - time_start\n",
    "    print('best combination (ACC: %.3f): %s\\n' % (sfs1.k_score_, sfs1.k_feature_idx_), time_run)\n",
    "    \n",
    "    d = {\"model\": m, \"score\": sfs1.k_score_, \"combination\": sfs1.k_feature_idx_}\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kukkojoo/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best combination (ACC: 0.889): (3, 12, 20, 23, 29, 31, 34, 40, 43, 53, 69, 70, 77, 80, 83, 92, 96)\n",
      " 626.5888030529022\n",
      "best combination (ACC: 0.882): (0, 2, 4, 5, 6, 9, 10, 11, 12, 17, 18, 20, 25, 31, 32, 33, 39, 42, 47, 48, 49, 50, 52, 53, 54, 56, 57, 61, 62, 63, 64, 67, 69, 74, 75, 76, 79, 85, 89, 91, 94, 98)\n",
      " 848.2930130958557\n",
      "best combination (ACC: 0.865): (0, 4, 10, 11, 12, 16, 18, 48, 49, 51, 53, 54, 55, 57, 58, 69, 70, 84, 86, 98, 99)\n",
      " 18.885116815567017\n",
      "best combination (ACC: 0.898): (10, 12, 15, 17, 21, 24, 50, 67, 68, 70, 71, 80, 98, 99)\n",
      " 172.72309827804565\n",
      "best combination (ACC: 0.898): (16, 70, 71, 80, 82, 98)\n",
      " 35.30685496330261\n",
      "1701.8022410869598\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score</th>\n",
       "      <th>combination</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier(class_weight={0: 0.45, ...</td>\n",
       "      <td>0.888792</td>\n",
       "      <td>(3, 12, 20, 23, 29, 31, 34, 40, 43, 53, 69, 70...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegressionCV(max_iter=10)</td>\n",
       "      <td>0.882271</td>\n",
       "      <td>(0, 2, 4, 5, 6, 9, 10, 11, 12, 17, 18, 20, 25,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>0.864879</td>\n",
       "      <td>(0, 4, 10, 11, 12, 16, 18, 48, 49, 51, 53, 54,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC(probability=True)</td>\n",
       "      <td>0.897585</td>\n",
       "      <td>(10, 12, 15, 17, 21, 24, 50, 67, 68, 70, 71, 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.897536</td>\n",
       "      <td>(16, 70, 71, 80, 82, 98)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model     score  \\\n",
       "0  RandomForestClassifier(class_weight={0: 0.45, ...  0.888792   \n",
       "1                  LogisticRegressionCV(max_iter=10)  0.882271   \n",
       "2                                       GaussianNB()  0.864879   \n",
       "3                              SVC(probability=True)  0.897585   \n",
       "4                             KNeighborsClassifier()  0.897536   \n",
       "\n",
       "                                         combination  \n",
       "0  (3, 12, 20, 23, 29, 31, 34, 40, 43, 53, 69, 70...  \n",
       "1  (0, 2, 4, 5, 6, 9, 10, 11, 12, 17, 18, 20, 25,...  \n",
       "2  (0, 4, 10, 11, 12, 16, 18, 48, 49, 51, 53, 54,...  \n",
       "3  (10, 12, 15, 17, 21, 24, 50, 67, 68, 70, 71, 8...  \n",
       "4                           (16, 70, 71, 80, 82, 98)  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "#X_train, X_test, y_train, y_test = splitAndScaleDate(X, y)\n",
    "scores = [runModel(m, X.iloc[:, 0:100], y) for m in models]\n",
    "results = pd.DataFrame(scores)\n",
    "time_end = time.time()\n",
    "print(time_end - time_start)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time\n",
    "* 20 -> 38s\n",
    "* 30 -> 85s\n",
    "* 40 -> 155s best score: 0.856\n",
    "* 50 -> 244s best score: 0.853\n",
    "* 60 -> 358s best score: 0.856\n",
    "* 70 -> 488s best score: 0.880\n",
    "* 80 -> 644s best score: 0.884\n",
    "* 90 -> 834s best score: 0.893"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 101\n",
    "#max = 0\n",
    "#best_shape = 0\n",
    "#best_model = \"\"\n",
    "#for i in range(1, 101):\n",
    "#    #print(df_.iloc[:, 0:i].shape)\n",
    "#    #print(i)\n",
    "#    X_train, X_test, y_train, y_test = splitAndScaleDate(df_.iloc[:, 0:i], y)\n",
    "#    scores = [runModel(m, X_train, X_test, y_train, y_test) for m in models]\n",
    "#    results = pd.DataFrame(scores)\n",
    "#    test_scores = results['test score'].to_numpy()\n",
    "#    \n",
    "#    if (np.amax(test_scores) > max):\n",
    "#        max = np.amax(test_scores)\n",
    "#        best_shape = df_.iloc[:, 0:i].shape\n",
    "#        \n",
    "#print(max)\n",
    "#print(best_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(458, 100)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train score</th>\n",
       "      <th>test score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', m...</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.855263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegressionCV(max_iter=1000)</td>\n",
       "      <td>0.918301</td>\n",
       "      <td>0.815789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>0.810458</td>\n",
       "      <td>0.763158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC(probability=True)</td>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.835526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.815789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model  train score  test score\n",
       "0  (DecisionTreeClassifier(max_features='auto', m...     0.944444    0.855263\n",
       "1                LogisticRegressionCV(max_iter=1000)     0.918301    0.815789\n",
       "2                                       GaussianNB()     0.810458    0.763158\n",
       "3                              SVC(probability=True)     0.921569    0.835526\n",
       "4                             KNeighborsClassifier()     0.911765    0.815789"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_.iloc[:, 0:101].shape)\n",
    "X_train, X_test, y_train, y_test = splitAndScaleDate(df_.iloc[:, 0:101], y)\n",
    "scores = [runModel(m, X_train, X_test, y_train, y_test) for m in models]\n",
    "results = pd.DataFrame(scores)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kukkojoo/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "classifier_pipeline = make_pipeline(StandardScaler(), svm)\n",
    "cv = KFold(n_splits=10, random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs1 = SFS(classifier_pipeline, \n",
    "           k_features=(1, 20), \n",
    "           forward=True, \n",
    "           scoring='accuracy',\n",
    "           cv=cv,\n",
    "           n_jobs=-1\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.27081799507141\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "sfs1.fit(X,y)\n",
    "time_end = time.time()\n",
    "print(time_end - time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'feature_idx': (70,),\n",
       "  'cv_scores': array([0.80434783, 0.84782609, 0.84782609, 0.7173913 , 0.7826087 ,\n",
       "         0.84782609, 0.7826087 , 0.63043478, 0.86666667, 0.73333333]),\n",
       "  'avg_score': 0.7860869565217391,\n",
       "  'feature_names': ('RHIRGA42.mean',)},\n",
       " 2: {'feature_idx': (12, 70),\n",
       "  'cv_scores': array([0.80434783, 0.86956522, 0.84782609, 0.76086957, 0.86956522,\n",
       "         0.91304348, 0.84782609, 0.86956522, 0.91111111, 0.84444444]),\n",
       "  'avg_score': 0.853816425120773,\n",
       "  'feature_names': ('H2O336.mean', 'RHIRGA42.mean')},\n",
       " 3: {'feature_idx': (12, 67, 70),\n",
       "  'cv_scores': array([0.86956522, 0.76086957, 0.86956522, 0.7826087 , 0.84782609,\n",
       "         0.93478261, 0.86956522, 0.82608696, 0.97777778, 0.86666667]),\n",
       "  'avg_score': 0.8605314009661835,\n",
       "  'feature_names': ('H2O336.mean', 'RHIRGA168.std', 'RHIRGA42.mean')},\n",
       " 4: {'feature_idx': (12, 67, 70, 80),\n",
       "  'cv_scores': array([0.84782609, 0.7826087 , 0.89130435, 0.7826087 , 0.86956522,\n",
       "         0.91304348, 0.91304348, 0.82608696, 0.95555556, 0.86666667]),\n",
       "  'avg_score': 0.8648309178743961,\n",
       "  'feature_names': ('H2O336.mean',\n",
       "   'RHIRGA168.std',\n",
       "   'RHIRGA42.mean',\n",
       "   'SO2168.mean')},\n",
       " 5: {'feature_idx': (12, 50, 67, 70, 80),\n",
       "  'cv_scores': array([0.86956522, 0.82608696, 0.89130435, 0.76086957, 0.86956522,\n",
       "         0.91304348, 0.89130435, 0.84782609, 0.97777778, 0.86666667]),\n",
       "  'avg_score': 0.8714009661835748,\n",
       "  'feature_names': ('H2O336.mean',\n",
       "   'O342.mean',\n",
       "   'RHIRGA168.std',\n",
       "   'RHIRGA42.mean',\n",
       "   'SO2168.mean')},\n",
       " 6: {'feature_idx': (12, 50, 67, 70, 71, 80),\n",
       "  'cv_scores': array([0.89130435, 0.82608696, 0.89130435, 0.7826087 , 0.84782609,\n",
       "         0.91304348, 0.91304348, 0.82608696, 0.95555556, 0.88888889]),\n",
       "  'avg_score': 0.8735748792270531,\n",
       "  'feature_names': ('H2O336.mean',\n",
       "   'O342.mean',\n",
       "   'RHIRGA168.std',\n",
       "   'RHIRGA42.mean',\n",
       "   'RHIRGA42.std',\n",
       "   'SO2168.mean')},\n",
       " 7: {'feature_idx': (12, 50, 67, 68, 70, 71, 80),\n",
       "  'cv_scores': array([0.89130435, 0.82608696, 0.89130435, 0.76086957, 0.86956522,\n",
       "         0.91304348, 0.93478261, 0.82608696, 0.97777778, 0.88888889]),\n",
       "  'avg_score': 0.8779710144927536,\n",
       "  'feature_names': ('H2O336.mean',\n",
       "   'O342.mean',\n",
       "   'RHIRGA168.std',\n",
       "   'RHIRGA336.mean',\n",
       "   'RHIRGA42.mean',\n",
       "   'RHIRGA42.std',\n",
       "   'SO2168.mean')},\n",
       " 8: {'feature_idx': (12, 15, 50, 67, 68, 70, 71, 80),\n",
       "  'cv_scores': array([0.91304348, 0.84782609, 0.86956522, 0.76086957, 0.86956522,\n",
       "         0.91304348, 0.91304348, 0.82608696, 0.97777778, 0.88888889]),\n",
       "  'avg_score': 0.8779710144927536,\n",
       "  'feature_names': ('H2O336.mean',\n",
       "   'H2O42.std',\n",
       "   'O342.mean',\n",
       "   'RHIRGA168.std',\n",
       "   'RHIRGA336.mean',\n",
       "   'RHIRGA42.mean',\n",
       "   'RHIRGA42.std',\n",
       "   'SO2168.mean')},\n",
       " 9: {'feature_idx': (12, 15, 50, 67, 68, 70, 71, 80, 98),\n",
       "  'cv_scores': array([0.93478261, 0.82608696, 0.89130435, 0.7826087 , 0.84782609,\n",
       "         0.93478261, 0.89130435, 0.84782609, 0.97777778, 0.84444444]),\n",
       "  'avg_score': 0.8778743961352656,\n",
       "  'feature_names': ('H2O336.mean',\n",
       "   'H2O42.std',\n",
       "   'O342.mean',\n",
       "   'RHIRGA168.std',\n",
       "   'RHIRGA336.mean',\n",
       "   'RHIRGA42.mean',\n",
       "   'RHIRGA42.std',\n",
       "   'SO2168.mean',\n",
       "   'CS.mean')},\n",
       " 10: {'feature_idx': (12, 15, 50, 67, 68, 70, 71, 80, 98, 99),\n",
       "  'cv_scores': array([0.91304348, 0.84782609, 0.89130435, 0.76086957, 0.91304348,\n",
       "         0.93478261, 0.93478261, 0.86956522, 0.97777778, 0.88888889]),\n",
       "  'avg_score': 0.8931884057971015,\n",
       "  'feature_names': ('H2O336.mean',\n",
       "   'H2O42.std',\n",
       "   'O342.mean',\n",
       "   'RHIRGA168.std',\n",
       "   'RHIRGA336.mean',\n",
       "   'RHIRGA42.mean',\n",
       "   'RHIRGA42.std',\n",
       "   'SO2168.mean',\n",
       "   'CS.mean',\n",
       "   'CS.std')},\n",
       " 11: {'feature_idx': (12, 15, 24, 50, 67, 68, 70, 71, 80, 98, 99),\n",
       "  'cv_scores': array([0.91304348, 0.84782609, 0.89130435, 0.76086957, 0.91304348,\n",
       "         0.93478261, 0.93478261, 0.86956522, 0.97777778, 0.88888889]),\n",
       "  'avg_score': 0.8931884057971015,\n",
       "  'feature_names': ('H2O336.mean',\n",
       "   'H2O42.std',\n",
       "   'NO168.mean',\n",
       "   'O342.mean',\n",
       "   'RHIRGA168.std',\n",
       "   'RHIRGA336.mean',\n",
       "   'RHIRGA42.mean',\n",
       "   'RHIRGA42.std',\n",
       "   'SO2168.mean',\n",
       "   'CS.mean',\n",
       "   'CS.std')},\n",
       " 12: {'feature_idx': (12, 15, 17, 24, 50, 67, 68, 70, 71, 80, 98, 99),\n",
       "  'cv_scores': array([0.89130435, 0.86956522, 0.89130435, 0.7826087 , 0.91304348,\n",
       "         0.93478261, 0.93478261, 0.86956522, 0.97777778, 0.86666667]),\n",
       "  'avg_score': 0.8931400966183576,\n",
       "  'feature_names': ('H2O336.mean',\n",
       "   'H2O42.std',\n",
       "   'H2O504.std',\n",
       "   'NO168.mean',\n",
       "   'O342.mean',\n",
       "   'RHIRGA168.std',\n",
       "   'RHIRGA336.mean',\n",
       "   'RHIRGA42.mean',\n",
       "   'RHIRGA42.std',\n",
       "   'SO2168.mean',\n",
       "   'CS.mean',\n",
       "   'CS.std')},\n",
       " 13: {'feature_idx': (10, 12, 15, 17, 24, 50, 67, 68, 70, 71, 80, 98, 99),\n",
       "  'cv_scores': array([0.91304348, 0.86956522, 0.89130435, 0.7826087 , 0.89130435,\n",
       "         0.93478261, 0.93478261, 0.86956522, 0.97777778, 0.88888889]),\n",
       "  'avg_score': 0.8953623188405798,\n",
       "  'feature_names': ('H2O168.mean',\n",
       "   'H2O336.mean',\n",
       "   'H2O42.std',\n",
       "   'H2O504.std',\n",
       "   'NO168.mean',\n",
       "   'O342.mean',\n",
       "   'RHIRGA168.std',\n",
       "   'RHIRGA336.mean',\n",
       "   'RHIRGA42.mean',\n",
       "   'RHIRGA42.std',\n",
       "   'SO2168.mean',\n",
       "   'CS.mean',\n",
       "   'CS.std')},\n",
       " 14: {'feature_idx': (10, 12, 15, 17, 21, 24, 50, 67, 68, 70, 71, 80, 98, 99),\n",
       "  'cv_scores': array([0.89130435, 0.86956522, 0.89130435, 0.80434783, 0.89130435,\n",
       "         0.93478261, 0.93478261, 0.86956522, 0.97777778, 0.91111111]),\n",
       "  'avg_score': 0.897584541062802,\n",
       "  'feature_names': ('H2O168.mean',\n",
       "   'H2O336.mean',\n",
       "   'H2O42.std',\n",
       "   'H2O504.std',\n",
       "   'H2O84.std',\n",
       "   'NO168.mean',\n",
       "   'O342.mean',\n",
       "   'RHIRGA168.std',\n",
       "   'RHIRGA336.mean',\n",
       "   'RHIRGA42.mean',\n",
       "   'RHIRGA42.std',\n",
       "   'SO2168.mean',\n",
       "   'CS.mean',\n",
       "   'CS.std')},\n",
       " 15: {'feature_idx': (10,\n",
       "   12,\n",
       "   14,\n",
       "   15,\n",
       "   17,\n",
       "   21,\n",
       "   24,\n",
       "   50,\n",
       "   67,\n",
       "   68,\n",
       "   70,\n",
       "   71,\n",
       "   80,\n",
       "   98,\n",
       "   99),\n",
       "  'cv_scores': array([0.89130435, 0.86956522, 0.89130435, 0.80434783, 0.89130435,\n",
       "         0.93478261, 0.93478261, 0.86956522, 0.97777778, 0.91111111]),\n",
       "  'avg_score': 0.897584541062802,\n",
       "  'feature_names': ('H2O168.mean',\n",
       "   'H2O336.mean',\n",
       "   'H2O42.mean',\n",
       "   'H2O42.std',\n",
       "   'H2O504.std',\n",
       "   'H2O84.std',\n",
       "   'NO168.mean',\n",
       "   'O342.mean',\n",
       "   'RHIRGA168.std',\n",
       "   'RHIRGA336.mean',\n",
       "   'RHIRGA42.mean',\n",
       "   'RHIRGA42.std',\n",
       "   'SO2168.mean',\n",
       "   'CS.mean',\n",
       "   'CS.std')},\n",
       " 16: {'feature_idx': (10,\n",
       "   12,\n",
       "   14,\n",
       "   15,\n",
       "   17,\n",
       "   21,\n",
       "   24,\n",
       "   48,\n",
       "   50,\n",
       "   67,\n",
       "   68,\n",
       "   70,\n",
       "   71,\n",
       "   80,\n",
       "   98,\n",
       "   99),\n",
       "  'cv_scores': array([0.86956522, 0.89130435, 0.89130435, 0.80434783, 0.89130435,\n",
       "         0.93478261, 0.93478261, 0.86956522, 0.97777778, 0.91111111]),\n",
       "  'avg_score': 0.897584541062802,\n",
       "  'feature_names': ('H2O168.mean',\n",
       "   'H2O336.mean',\n",
       "   'H2O42.mean',\n",
       "   'H2O42.std',\n",
       "   'H2O504.std',\n",
       "   'H2O84.std',\n",
       "   'NO168.mean',\n",
       "   'O3168.mean',\n",
       "   'O342.mean',\n",
       "   'RHIRGA168.std',\n",
       "   'RHIRGA336.mean',\n",
       "   'RHIRGA42.mean',\n",
       "   'RHIRGA42.std',\n",
       "   'SO2168.mean',\n",
       "   'CS.mean',\n",
       "   'CS.std')},\n",
       " 17: {'feature_idx': (10,\n",
       "   12,\n",
       "   14,\n",
       "   15,\n",
       "   17,\n",
       "   21,\n",
       "   24,\n",
       "   26,\n",
       "   48,\n",
       "   50,\n",
       "   67,\n",
       "   68,\n",
       "   70,\n",
       "   71,\n",
       "   80,\n",
       "   98,\n",
       "   99),\n",
       "  'cv_scores': array([0.86956522, 0.89130435, 0.89130435, 0.80434783, 0.89130435,\n",
       "         0.93478261, 0.93478261, 0.86956522, 0.97777778, 0.91111111]),\n",
       "  'avg_score': 0.897584541062802,\n",
       "  'feature_names': ('H2O168.mean',\n",
       "   'H2O336.mean',\n",
       "   'H2O42.mean',\n",
       "   'H2O42.std',\n",
       "   'H2O504.std',\n",
       "   'H2O84.std',\n",
       "   'NO168.mean',\n",
       "   'NO336.mean',\n",
       "   'O3168.mean',\n",
       "   'O342.mean',\n",
       "   'RHIRGA168.std',\n",
       "   'RHIRGA336.mean',\n",
       "   'RHIRGA42.mean',\n",
       "   'RHIRGA42.std',\n",
       "   'SO2168.mean',\n",
       "   'CS.mean',\n",
       "   'CS.std')},\n",
       " 18: {'feature_idx': (10,\n",
       "   11,\n",
       "   12,\n",
       "   14,\n",
       "   15,\n",
       "   17,\n",
       "   21,\n",
       "   24,\n",
       "   26,\n",
       "   48,\n",
       "   50,\n",
       "   67,\n",
       "   68,\n",
       "   70,\n",
       "   71,\n",
       "   80,\n",
       "   98,\n",
       "   99),\n",
       "  'cv_scores': array([0.89130435, 0.89130435, 0.89130435, 0.80434783, 0.89130435,\n",
       "         0.93478261, 0.93478261, 0.84782609, 0.97777778, 0.91111111]),\n",
       "  'avg_score': 0.897584541062802,\n",
       "  'feature_names': ('H2O168.mean',\n",
       "   'H2O168.std',\n",
       "   'H2O336.mean',\n",
       "   'H2O42.mean',\n",
       "   'H2O42.std',\n",
       "   'H2O504.std',\n",
       "   'H2O84.std',\n",
       "   'NO168.mean',\n",
       "   'NO336.mean',\n",
       "   'O3168.mean',\n",
       "   'O342.mean',\n",
       "   'RHIRGA168.std',\n",
       "   'RHIRGA336.mean',\n",
       "   'RHIRGA42.mean',\n",
       "   'RHIRGA42.std',\n",
       "   'SO2168.mean',\n",
       "   'CS.mean',\n",
       "   'CS.std')},\n",
       " 19: {'feature_idx': (10,\n",
       "   11,\n",
       "   12,\n",
       "   14,\n",
       "   15,\n",
       "   17,\n",
       "   21,\n",
       "   24,\n",
       "   26,\n",
       "   48,\n",
       "   50,\n",
       "   66,\n",
       "   67,\n",
       "   68,\n",
       "   70,\n",
       "   71,\n",
       "   80,\n",
       "   98,\n",
       "   99),\n",
       "  'cv_scores': array([0.89130435, 0.89130435, 0.89130435, 0.80434783, 0.89130435,\n",
       "         0.93478261, 0.93478261, 0.84782609, 0.97777778, 0.91111111]),\n",
       "  'avg_score': 0.897584541062802,\n",
       "  'feature_names': ('H2O168.mean',\n",
       "   'H2O168.std',\n",
       "   'H2O336.mean',\n",
       "   'H2O42.mean',\n",
       "   'H2O42.std',\n",
       "   'H2O504.std',\n",
       "   'H2O84.std',\n",
       "   'NO168.mean',\n",
       "   'NO336.mean',\n",
       "   'O3168.mean',\n",
       "   'O342.mean',\n",
       "   'RHIRGA168.mean',\n",
       "   'RHIRGA168.std',\n",
       "   'RHIRGA336.mean',\n",
       "   'RHIRGA42.mean',\n",
       "   'RHIRGA42.std',\n",
       "   'SO2168.mean',\n",
       "   'CS.mean',\n",
       "   'CS.std')},\n",
       " 20: {'feature_idx': (10,\n",
       "   11,\n",
       "   12,\n",
       "   14,\n",
       "   15,\n",
       "   17,\n",
       "   21,\n",
       "   24,\n",
       "   26,\n",
       "   48,\n",
       "   50,\n",
       "   66,\n",
       "   67,\n",
       "   68,\n",
       "   70,\n",
       "   71,\n",
       "   76,\n",
       "   80,\n",
       "   98,\n",
       "   99),\n",
       "  'cv_scores': array([0.86956522, 0.89130435, 0.89130435, 0.80434783, 0.91304348,\n",
       "         0.93478261, 0.93478261, 0.84782609, 0.97777778, 0.91111111]),\n",
       "  'avg_score': 0.8975845410628018,\n",
       "  'feature_names': ('H2O168.mean',\n",
       "   'H2O168.std',\n",
       "   'H2O336.mean',\n",
       "   'H2O42.mean',\n",
       "   'H2O42.std',\n",
       "   'H2O504.std',\n",
       "   'H2O84.std',\n",
       "   'NO168.mean',\n",
       "   'NO336.mean',\n",
       "   'O3168.mean',\n",
       "   'O342.mean',\n",
       "   'RHIRGA168.mean',\n",
       "   'RHIRGA168.std',\n",
       "   'RHIRGA336.mean',\n",
       "   'RHIRGA42.mean',\n",
       "   'RHIRGA42.std',\n",
       "   'RHIRGA84.mean',\n",
       "   'SO2168.mean',\n",
       "   'CS.mean',\n",
       "   'CS.std')}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfs1.subsets_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best combination (ACC: 0.898): (10, 12, 15, 17, 21, 24, 50, 67, 68, 70, 71, 80, 98, 99)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('best combination (ACC: %.3f): %s\\n' % (sfs1.k_score_, sfs1.k_feature_idx_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimiseModelParams(model: ClassifierMixin, paramDistributions: dict, x: ndarray, y: ndarray, n_iterations: int=20, k_folds: int=10):\n",
    "    kfolds = RepeatedStratifiedKFold(n_splits=k_folds, n_repeats=n_iterations)\n",
    "    searcher = RandomizedSearchCV(estimator=model, param_distributions=paramDistributions, n_iter = n_iterations, n_jobs=-1, refit=True, cv=kfolds)\n",
    "    searcher.fit(x,y)\n",
    "    #pickle.dump(pd.DataFrame(searcher.cv_results_), open(f'{getNiceModelName(model)}-parameter_tuning.pickle', 'wb'))\n",
    "    return searcher.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runModelStepwiseSelection(model: ClassifierMixin, x: ndarray, y: ndarray):\n",
    "    \n",
    "    modelParams = []\n",
    "    \n",
    "    time_start = time.time()\n",
    "    \n",
    "    if model == None:\n",
    "        raise ValueError(\"no model supplied\")\n",
    "    if not isinstance(model, ClassifierMixin):\n",
    "        warn(\"did you pass a valid sklearn model?\")\n",
    "    \n",
    "    classifier_pipeline = make_pipeline(StandardScaler(), model)\n",
    "    \n",
    "    cv = KFold(n_splits=10, random_state=0, shuffle=False)\n",
    "\n",
    "    sfs1 = SFS(classifier_pipeline, \n",
    "        k_features=(1, 100), \n",
    "        forward=True, \n",
    "        scoring='accuracy',\n",
    "        cv=cv,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    sfs1.fit(X,y)\n",
    "    time_end = time.time()\n",
    "    time_run = time_end - time_start\n",
    "    print(model, time_run)\n",
    "    #print('best combination (ACC: %.3f): %s\\n' % (sfs1.k_score_, sfs1.k_feature_idx_), time_run)\n",
    "    \n",
    "    \n",
    "    return {\"model\": model, \"features\": sfs1.k_feature_idx_, \"scores\": sfs1.k_score_}\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(probability=True)\n",
    "svm_params = dict(C=uniform(loc=0, scale=4), kernel=['sigmoid', 'rbf', 'poly'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(class_weight={0: 0.45, 1: 0.55}, min_samples_leaf=5,\n",
      "                       min_samples_split=5, n_estimators=50, random_state=42) 596.1331169605255\n",
      "LogisticRegressionCV(max_iter=10) 834.5605890750885\n",
      "GaussianNB() 19.370463848114014\n",
      "SVC(probability=True) 168.49733591079712\n",
      "KNeighborsClassifier() 34.474915981292725\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for m in models:\n",
    "    results.append(runModelStepwiseSelection(m, X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': RandomForestClassifier(class_weight={0: 0.45, 1: 0.55}, min_samples_leaf=5,\n",
      "                       min_samples_split=5, n_estimators=50, random_state=42), 'features': (3, 12, 20, 23, 29, 31, 34, 40, 43, 53, 69, 70, 77, 80, 83, 92, 96), 'scores': 0.888792270531401}\n",
      "\n",
      "{'model': LogisticRegressionCV(max_iter=10), 'features': (0, 2, 4, 5, 6, 9, 10, 11, 12, 17, 18, 20, 25, 31, 32, 33, 39, 42, 47, 48, 49, 50, 52, 53, 54, 56, 57, 61, 62, 63, 64, 67, 69, 74, 75, 76, 79, 85, 89, 91, 94, 98), 'scores': 0.8822705314009662}\n",
      "\n",
      "{'model': GaussianNB(), 'features': (0, 4, 10, 11, 12, 16, 18, 48, 49, 51, 53, 54, 55, 57, 58, 69, 70, 84, 86, 98, 99), 'scores': 0.8648792270531402}\n",
      "\n",
      "{'model': SVC(probability=True), 'features': (10, 12, 15, 17, 21, 24, 50, 67, 68, 70, 71, 80, 98, 99), 'scores': 0.897584541062802}\n",
      "\n",
      "{'model': KNeighborsClassifier(), 'features': (16, 70, 71, 80, 82, 98), 'scores': 0.897536231884058}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for r in results:\n",
    "    print(r)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t = X.iloc[:, [10, 12, 15, 17, 21, 24, 50, 67, 68, 70, 71, 80, 98, 99]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = SVC(probability=True)\n",
    "X_train, X_test, y_train, y_test = splitAndScaleDate(x_t, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(probability=True)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.fit (X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8921568627450981"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.875"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('SVC', 0.9084967320261438, 11.486924123757571, 0.875, 8.327975103570852)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = SVC(probability=True)\n",
    "runModel(s, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(probability=True)\n",
    "svm_params = dict(C=uniform(loc=0, scale=4), kernel=['sigmoid', 'rbf', 'poly'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr_params = dict(C=uniform(loc=0, scale=4), penalty=['l2'], solver=['newton-cg', 'lbfgs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_num = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaled = scaling(x_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runModelCV call done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(        Train Accuracy  Train Perplex  Validation Accuracy  \\\n",
       " SVC-1         0.891304       8.530523             0.863388   \n",
       " SVC-2         0.956522       8.409353             0.838798   \n",
       " SVC-3         0.923913       7.957444             0.860656   \n",
       " SVC-4         0.934066       9.300850             0.863760   \n",
       " SVC-5         0.923077      12.714039             0.847411   \n",
       " SVC-6         0.934783       9.124257             0.811475   \n",
       " SVC-7         0.945652      12.855980             0.868852   \n",
       " SVC-8         0.934783       9.785516             0.836066   \n",
       " SVC-9         0.923077       7.738531             0.869210   \n",
       " SVC-10        0.934066       9.177957             0.855586   \n",
       " SVC-11        0.923913      10.259293             0.871585   \n",
       " SVC-12        0.934783       8.047806             0.890710   \n",
       " SVC-13        0.902174       5.211004             0.877049   \n",
       " SVC-14        0.945055       9.265611             0.877384   \n",
       " SVC-15        0.934066       6.824286             0.858311   \n",
       " SVC-16        0.945652      16.154292             0.866120   \n",
       " SVC-17        0.934783      10.765277             0.833333   \n",
       " SVC-18        0.945652       8.560446             0.874317   \n",
       " SVC-19        0.923077       6.480732             0.858311   \n",
       " SVC-20        0.890110       6.839220             0.852861   \n",
       " SVC-21        0.934783       8.114893             0.863388   \n",
       " SVC-22        0.913043       6.699054             0.857923   \n",
       " SVC-23        0.967391      10.180340             0.852459   \n",
       " SVC-24        0.934066      12.023210             0.863760   \n",
       " SVC-25        0.934066       7.456203             0.833787   \n",
       " \n",
       "         Validation Perplex                                      Params  \n",
       " SVC-1             6.615447  {'C': 2.0462943442158426, 'kernel': 'rbf'}  \n",
       " SVC-2             5.891002  {'C': 2.0462943442158426, 'kernel': 'rbf'}  \n",
       " SVC-3             6.414163  {'C': 2.0462943442158426, 'kernel': 'rbf'}  \n",
       " SVC-4             7.381956  {'C': 2.0462943442158426, 'kernel': 'rbf'}  \n",
       " SVC-5            10.343850  {'C': 2.0462943442158426, 'kernel': 'rbf'}  \n",
       " SVC-6             6.385568  {'C': 2.0462943442158426, 'kernel': 'rbf'}  \n",
       " SVC-7             9.416768  {'C': 2.0462943442158426, 'kernel': 'rbf'}  \n",
       " SVC-8             7.365171  {'C': 2.0462943442158426, 'kernel': 'rbf'}  \n",
       " SVC-9             5.521991  {'C': 2.0462943442158426, 'kernel': 'rbf'}  \n",
       " SVC-10            6.371461  {'C': 2.0462943442158426, 'kernel': 'rbf'}  \n",
       " SVC-11            7.275888  {'C': 2.0462943442158426, 'kernel': 'rbf'}  \n",
       " SVC-12            6.749500  {'C': 2.0462943442158426, 'kernel': 'rbf'}  \n",
       " SVC-13            4.696004  {'C': 2.0462943442158426, 'kernel': 'rbf'}  \n",
       " SVC-14            6.677177  {'C': 2.0462943442158426, 'kernel': 'rbf'}  \n",
       " SVC-15            5.387367  {'C': 2.0462943442158426, 'kernel': 'rbf'}  \n",
       " SVC-16           11.526740  {'C': 2.0462943442158426, 'kernel': 'rbf'}  \n",
       " SVC-17            7.146904  {'C': 2.0462943442158426, 'kernel': 'rbf'}  \n",
       " SVC-18            6.041618  {'C': 2.0462943442158426, 'kernel': 'rbf'}  \n",
       " SVC-19            6.564437  {'C': 2.0462943442158426, 'kernel': 'rbf'}  \n",
       " SVC-20            5.591676  {'C': 2.0462943442158426, 'kernel': 'rbf'}  \n",
       " SVC-21            5.814657  {'C': 2.0462943442158426, 'kernel': 'rbf'}  \n",
       " SVC-22            5.378123  {'C': 2.0462943442158426, 'kernel': 'rbf'}  \n",
       " SVC-23            7.097666  {'C': 2.0462943442158426, 'kernel': 'rbf'}  \n",
       " SVC-24            9.512080  {'C': 2.0462943442158426, 'kernel': 'rbf'}  \n",
       " SVC-25            6.274997  {'C': 2.0462943442158426, 'kernel': 'rbf'}  ,\n",
       " {'SVC-1': SVC(C=2.0462943442158426, probability=True),\n",
       "  'SVC-2': SVC(C=2.0462943442158426, probability=True),\n",
       "  'SVC-3': SVC(C=2.0462943442158426, probability=True),\n",
       "  'SVC-4': SVC(C=2.0462943442158426, probability=True),\n",
       "  'SVC-5': SVC(C=2.0462943442158426, probability=True),\n",
       "  'SVC-6': SVC(C=2.0462943442158426, probability=True),\n",
       "  'SVC-7': SVC(C=2.0462943442158426, probability=True),\n",
       "  'SVC-8': SVC(C=2.0462943442158426, probability=True),\n",
       "  'SVC-9': SVC(C=2.0462943442158426, probability=True),\n",
       "  'SVC-10': SVC(C=2.0462943442158426, probability=True),\n",
       "  'SVC-11': SVC(C=2.0462943442158426, probability=True),\n",
       "  'SVC-12': SVC(C=2.0462943442158426, probability=True),\n",
       "  'SVC-13': SVC(C=2.0462943442158426, probability=True),\n",
       "  'SVC-14': SVC(C=2.0462943442158426, probability=True),\n",
       "  'SVC-15': SVC(C=2.0462943442158426, probability=True),\n",
       "  'SVC-16': SVC(C=2.0462943442158426, probability=True),\n",
       "  'SVC-17': SVC(C=2.0462943442158426, probability=True),\n",
       "  'SVC-18': SVC(C=2.0462943442158426, probability=True),\n",
       "  'SVC-19': SVC(C=2.0462943442158426, probability=True),\n",
       "  'SVC-20': SVC(C=2.0462943442158426, probability=True),\n",
       "  'SVC-21': SVC(C=2.0462943442158426, probability=True),\n",
       "  'SVC-22': SVC(C=2.0462943442158426, probability=True),\n",
       "  'SVC-23': SVC(C=2.0462943442158426, probability=True),\n",
       "  'SVC-24': SVC(C=2.0462943442158426, probability=True),\n",
       "  'SVC-25': SVC(C=2.0462943442158426, probability=True)})"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t = X.iloc[:, [10, 12, 15, 17, 21, 24, 50, 67, 68, 70, 71, 80, 98, 99]]\n",
    "[x_PCA, pca] = training_with_PCA(x_t,PCA_num)\n",
    "runModelCV(svm, svm_params, x_scaled, y, 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runModelCV call done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                       Train Accuracy  Train Perplex  Validation Accuracy  \\\n",
       " LogisticRegression-1         0.869565      22.254417             0.819672   \n",
       " LogisticRegression-2         0.913043      17.326000             0.855191   \n",
       " LogisticRegression-3         0.880435       9.816967             0.822404   \n",
       " LogisticRegression-4         0.901099      20.860745             0.847411   \n",
       " LogisticRegression-5         0.945055      39.194169             0.828338   \n",
       " LogisticRegression-6         0.934783      58.986569             0.844262   \n",
       " LogisticRegression-7         0.913043      15.546377             0.836066   \n",
       " LogisticRegression-8         0.934783      25.644328             0.830601   \n",
       " LogisticRegression-9         0.934066      15.786413             0.828338   \n",
       " LogisticRegression-10        0.934066      20.701636             0.825613   \n",
       " LogisticRegression-11        0.902174      12.396270             0.822404   \n",
       " LogisticRegression-12        0.891304      10.641659             0.836066   \n",
       " LogisticRegression-13        0.913043      17.865082             0.866120   \n",
       " LogisticRegression-14        0.956044      33.108688             0.844687   \n",
       " LogisticRegression-15        0.956044      35.756750             0.825613   \n",
       " LogisticRegression-16        0.880435      14.532616             0.833333   \n",
       " LogisticRegression-17        0.913043      22.086908             0.846995   \n",
       " LogisticRegression-18        0.934783      19.188090             0.836066   \n",
       " LogisticRegression-19        0.967033      50.884624             0.852861   \n",
       " LogisticRegression-20        0.879121      12.393104             0.839237   \n",
       " LogisticRegression-21        0.913043      24.195716             0.797814   \n",
       " LogisticRegression-22        0.956522      39.816369             0.827869   \n",
       " LogisticRegression-23        0.923913      38.747297             0.825137   \n",
       " LogisticRegression-24        0.868132      10.880710             0.844687   \n",
       " LogisticRegression-25        0.912088      12.988574             0.855586   \n",
       " \n",
       "                        Validation Perplex  \\\n",
       " LogisticRegression-1            17.849297   \n",
       " LogisticRegression-2            14.700182   \n",
       " LogisticRegression-3             9.567378   \n",
       " LogisticRegression-4            17.446130   \n",
       " LogisticRegression-5            26.868915   \n",
       " LogisticRegression-6            41.377218   \n",
       " LogisticRegression-7            14.608665   \n",
       " LogisticRegression-8            26.160269   \n",
       " LogisticRegression-9            11.337579   \n",
       " LogisticRegression-10           17.853002   \n",
       " LogisticRegression-11           11.815862   \n",
       " LogisticRegression-12           12.358331   \n",
       " LogisticRegression-13           13.488080   \n",
       " LogisticRegression-14           29.282679   \n",
       " LogisticRegression-15           25.094250   \n",
       " LogisticRegression-16           16.843920   \n",
       " LogisticRegression-17           21.840527   \n",
       " LogisticRegression-18           13.892952   \n",
       " LogisticRegression-19           25.354544   \n",
       " LogisticRegression-20           12.486978   \n",
       " LogisticRegression-21           14.706962   \n",
       " LogisticRegression-22           23.176749   \n",
       " LogisticRegression-23           27.265984   \n",
       " LogisticRegression-24            9.450615   \n",
       " LogisticRegression-25           15.682781   \n",
       " \n",
       "                                                                   Params  \n",
       " LogisticRegression-1   {'C': 0.9612119472951637, 'penalty': 'l2', 'so...  \n",
       " LogisticRegression-2   {'C': 0.9612119472951637, 'penalty': 'l2', 'so...  \n",
       " LogisticRegression-3   {'C': 0.9612119472951637, 'penalty': 'l2', 'so...  \n",
       " LogisticRegression-4   {'C': 0.9612119472951637, 'penalty': 'l2', 'so...  \n",
       " LogisticRegression-5   {'C': 0.9612119472951637, 'penalty': 'l2', 'so...  \n",
       " LogisticRegression-6   {'C': 0.9612119472951637, 'penalty': 'l2', 'so...  \n",
       " LogisticRegression-7   {'C': 0.9612119472951637, 'penalty': 'l2', 'so...  \n",
       " LogisticRegression-8   {'C': 0.9612119472951637, 'penalty': 'l2', 'so...  \n",
       " LogisticRegression-9   {'C': 0.9612119472951637, 'penalty': 'l2', 'so...  \n",
       " LogisticRegression-10  {'C': 0.9612119472951637, 'penalty': 'l2', 'so...  \n",
       " LogisticRegression-11  {'C': 0.9612119472951637, 'penalty': 'l2', 'so...  \n",
       " LogisticRegression-12  {'C': 0.9612119472951637, 'penalty': 'l2', 'so...  \n",
       " LogisticRegression-13  {'C': 0.9612119472951637, 'penalty': 'l2', 'so...  \n",
       " LogisticRegression-14  {'C': 0.9612119472951637, 'penalty': 'l2', 'so...  \n",
       " LogisticRegression-15  {'C': 0.9612119472951637, 'penalty': 'l2', 'so...  \n",
       " LogisticRegression-16  {'C': 0.9612119472951637, 'penalty': 'l2', 'so...  \n",
       " LogisticRegression-17  {'C': 0.9612119472951637, 'penalty': 'l2', 'so...  \n",
       " LogisticRegression-18  {'C': 0.9612119472951637, 'penalty': 'l2', 'so...  \n",
       " LogisticRegression-19  {'C': 0.9612119472951637, 'penalty': 'l2', 'so...  \n",
       " LogisticRegression-20  {'C': 0.9612119472951637, 'penalty': 'l2', 'so...  \n",
       " LogisticRegression-21  {'C': 0.9612119472951637, 'penalty': 'l2', 'so...  \n",
       " LogisticRegression-22  {'C': 0.9612119472951637, 'penalty': 'l2', 'so...  \n",
       " LogisticRegression-23  {'C': 0.9612119472951637, 'penalty': 'l2', 'so...  \n",
       " LogisticRegression-24  {'C': 0.9612119472951637, 'penalty': 'l2', 'so...  \n",
       " LogisticRegression-25  {'C': 0.9612119472951637, 'penalty': 'l2', 'so...  ,\n",
       " {'LogisticRegression-1': LogisticRegression(C=0.9612119472951637),\n",
       "  'LogisticRegression-2': LogisticRegression(C=0.9612119472951637),\n",
       "  'LogisticRegression-3': LogisticRegression(C=0.9612119472951637),\n",
       "  'LogisticRegression-4': LogisticRegression(C=0.9612119472951637),\n",
       "  'LogisticRegression-5': LogisticRegression(C=0.9612119472951637),\n",
       "  'LogisticRegression-6': LogisticRegression(C=0.9612119472951637),\n",
       "  'LogisticRegression-7': LogisticRegression(C=0.9612119472951637),\n",
       "  'LogisticRegression-8': LogisticRegression(C=0.9612119472951637),\n",
       "  'LogisticRegression-9': LogisticRegression(C=0.9612119472951637),\n",
       "  'LogisticRegression-10': LogisticRegression(C=0.9612119472951637),\n",
       "  'LogisticRegression-11': LogisticRegression(C=0.9612119472951637),\n",
       "  'LogisticRegression-12': LogisticRegression(C=0.9612119472951637),\n",
       "  'LogisticRegression-13': LogisticRegression(C=0.9612119472951637),\n",
       "  'LogisticRegression-14': LogisticRegression(C=0.9612119472951637),\n",
       "  'LogisticRegression-15': LogisticRegression(C=0.9612119472951637),\n",
       "  'LogisticRegression-16': LogisticRegression(C=0.9612119472951637),\n",
       "  'LogisticRegression-17': LogisticRegression(C=0.9612119472951637),\n",
       "  'LogisticRegression-18': LogisticRegression(C=0.9612119472951637),\n",
       "  'LogisticRegression-19': LogisticRegression(C=0.9612119472951637),\n",
       "  'LogisticRegression-20': LogisticRegression(C=0.9612119472951637),\n",
       "  'LogisticRegression-21': LogisticRegression(C=0.9612119472951637),\n",
       "  'LogisticRegression-22': LogisticRegression(C=0.9612119472951637),\n",
       "  'LogisticRegression-23': LogisticRegression(C=0.9612119472951637),\n",
       "  'LogisticRegression-24': LogisticRegression(C=0.9612119472951637),\n",
       "  'LogisticRegression-25': LogisticRegression(C=0.9612119472951637)})"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t = X.iloc[:, [0, 2, 4, 5, 6, 9, 10, 11, 12, 17, 18, 20, 25, 31, 32, 33, 39, 42, 47, 48, 49, 50, 52, 53, 54, 56, 57, 61, 62, 63, 64, 67, 69, 74, 75, 76, 79, 85, 89, 91, 94, 98]]\n",
    "#[x_PCA, pca] = training_with_PCA(x_t,PCA_num)\n",
    "x_scaled = scaling(x_t)\n",
    "runModelCV(lr, lr_params, x_scaled, y, 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf_params = dict(min_samples_split=[2,3,4,5,6], min_samples_leaf=[1,2,3,4,5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runModelCV call done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                           Train Accuracy  Train Perplex  Validation Accuracy  \\\n",
       " RandomForestClassifier-1         0.913043       6.460607             0.857923   \n",
       " RandomForestClassifier-2         0.913043       6.072217             0.855191   \n",
       " RandomForestClassifier-3         0.923913       5.785159             0.830601   \n",
       " RandomForestClassifier-4         0.901099       7.118300             0.866485   \n",
       " RandomForestClassifier-5         0.890110       5.171134             0.871935   \n",
       " RandomForestClassifier-6         0.923913       5.826633             0.866120   \n",
       " RandomForestClassifier-7         0.880435       5.398261             0.822404   \n",
       " RandomForestClassifier-8         0.934783       7.460442             0.852459   \n",
       " RandomForestClassifier-9         0.901099       6.027355             0.852861   \n",
       " RandomForestClassifier-10        0.923077       7.799066             0.850136   \n",
       " RandomForestClassifier-11        0.934783       7.240443             0.844262   \n",
       " RandomForestClassifier-12        0.880435       5.023907             0.852459   \n",
       " RandomForestClassifier-13        0.934783       6.983098             0.849727   \n",
       " RandomForestClassifier-14        0.901099       5.861437             0.852861   \n",
       " RandomForestClassifier-15        0.934066       6.602494             0.855586   \n",
       " RandomForestClassifier-16        0.956522       6.651578             0.857923   \n",
       " RandomForestClassifier-17        0.902174       6.504146             0.852459   \n",
       " RandomForestClassifier-18        0.923913       5.864247             0.857923   \n",
       " RandomForestClassifier-19        0.890110       5.675752             0.855586   \n",
       " RandomForestClassifier-20        0.934066       6.276726             0.855586   \n",
       " RandomForestClassifier-21        0.956522       9.123368             0.846995   \n",
       " RandomForestClassifier-22        0.891304       4.864470             0.852459   \n",
       " RandomForestClassifier-23        0.913043       6.046115             0.846995   \n",
       " RandomForestClassifier-24        0.945055       6.608378             0.817439   \n",
       " RandomForestClassifier-25        0.945055       7.412977             0.822888   \n",
       " \n",
       "                            Validation Perplex  \\\n",
       " RandomForestClassifier-1             4.966939   \n",
       " RandomForestClassifier-2             4.954577   \n",
       " RandomForestClassifier-3             4.387565   \n",
       " RandomForestClassifier-4             4.914922   \n",
       " RandomForestClassifier-5             4.180678   \n",
       " RandomForestClassifier-6             4.782320   \n",
       " RandomForestClassifier-7             4.145304   \n",
       " RandomForestClassifier-8             5.151410   \n",
       " RandomForestClassifier-9             4.401560   \n",
       " RandomForestClassifier-10            5.612981   \n",
       " RandomForestClassifier-11            4.761965   \n",
       " RandomForestClassifier-12            4.335555   \n",
       " RandomForestClassifier-13            5.460848   \n",
       " RandomForestClassifier-14            4.522247   \n",
       " RandomForestClassifier-15            5.364913   \n",
       " RandomForestClassifier-16            5.049311   \n",
       " RandomForestClassifier-17            4.567296   \n",
       " RandomForestClassifier-18            4.503463   \n",
       " RandomForestClassifier-19            4.423494   \n",
       " RandomForestClassifier-20            4.640339   \n",
       " RandomForestClassifier-21            6.496726   \n",
       " RandomForestClassifier-22            4.011179   \n",
       " RandomForestClassifier-23            4.582563   \n",
       " RandomForestClassifier-24            4.513625   \n",
       " RandomForestClassifier-25            4.613413   \n",
       " \n",
       "                                                                     Params  \n",
       " RandomForestClassifier-1   {'min_samples_split': 2, 'min_samples_leaf': 6}  \n",
       " RandomForestClassifier-2   {'min_samples_split': 2, 'min_samples_leaf': 6}  \n",
       " RandomForestClassifier-3   {'min_samples_split': 2, 'min_samples_leaf': 6}  \n",
       " RandomForestClassifier-4   {'min_samples_split': 2, 'min_samples_leaf': 6}  \n",
       " RandomForestClassifier-5   {'min_samples_split': 2, 'min_samples_leaf': 6}  \n",
       " RandomForestClassifier-6   {'min_samples_split': 2, 'min_samples_leaf': 6}  \n",
       " RandomForestClassifier-7   {'min_samples_split': 2, 'min_samples_leaf': 6}  \n",
       " RandomForestClassifier-8   {'min_samples_split': 2, 'min_samples_leaf': 6}  \n",
       " RandomForestClassifier-9   {'min_samples_split': 2, 'min_samples_leaf': 6}  \n",
       " RandomForestClassifier-10  {'min_samples_split': 2, 'min_samples_leaf': 6}  \n",
       " RandomForestClassifier-11  {'min_samples_split': 2, 'min_samples_leaf': 6}  \n",
       " RandomForestClassifier-12  {'min_samples_split': 2, 'min_samples_leaf': 6}  \n",
       " RandomForestClassifier-13  {'min_samples_split': 2, 'min_samples_leaf': 6}  \n",
       " RandomForestClassifier-14  {'min_samples_split': 2, 'min_samples_leaf': 6}  \n",
       " RandomForestClassifier-15  {'min_samples_split': 2, 'min_samples_leaf': 6}  \n",
       " RandomForestClassifier-16  {'min_samples_split': 2, 'min_samples_leaf': 6}  \n",
       " RandomForestClassifier-17  {'min_samples_split': 2, 'min_samples_leaf': 6}  \n",
       " RandomForestClassifier-18  {'min_samples_split': 2, 'min_samples_leaf': 6}  \n",
       " RandomForestClassifier-19  {'min_samples_split': 2, 'min_samples_leaf': 6}  \n",
       " RandomForestClassifier-20  {'min_samples_split': 2, 'min_samples_leaf': 6}  \n",
       " RandomForestClassifier-21  {'min_samples_split': 2, 'min_samples_leaf': 6}  \n",
       " RandomForestClassifier-22  {'min_samples_split': 2, 'min_samples_leaf': 6}  \n",
       " RandomForestClassifier-23  {'min_samples_split': 2, 'min_samples_leaf': 6}  \n",
       " RandomForestClassifier-24  {'min_samples_split': 2, 'min_samples_leaf': 6}  \n",
       " RandomForestClassifier-25  {'min_samples_split': 2, 'min_samples_leaf': 6}  ,\n",
       " {'RandomForestClassifier-1': RandomForestClassifier(min_samples_leaf=6),\n",
       "  'RandomForestClassifier-2': RandomForestClassifier(min_samples_leaf=6),\n",
       "  'RandomForestClassifier-3': RandomForestClassifier(min_samples_leaf=6),\n",
       "  'RandomForestClassifier-4': RandomForestClassifier(min_samples_leaf=6),\n",
       "  'RandomForestClassifier-5': RandomForestClassifier(min_samples_leaf=6),\n",
       "  'RandomForestClassifier-6': RandomForestClassifier(min_samples_leaf=6),\n",
       "  'RandomForestClassifier-7': RandomForestClassifier(min_samples_leaf=6),\n",
       "  'RandomForestClassifier-8': RandomForestClassifier(min_samples_leaf=6),\n",
       "  'RandomForestClassifier-9': RandomForestClassifier(min_samples_leaf=6),\n",
       "  'RandomForestClassifier-10': RandomForestClassifier(min_samples_leaf=6),\n",
       "  'RandomForestClassifier-11': RandomForestClassifier(min_samples_leaf=6),\n",
       "  'RandomForestClassifier-12': RandomForestClassifier(min_samples_leaf=6),\n",
       "  'RandomForestClassifier-13': RandomForestClassifier(min_samples_leaf=6),\n",
       "  'RandomForestClassifier-14': RandomForestClassifier(min_samples_leaf=6),\n",
       "  'RandomForestClassifier-15': RandomForestClassifier(min_samples_leaf=6),\n",
       "  'RandomForestClassifier-16': RandomForestClassifier(min_samples_leaf=6),\n",
       "  'RandomForestClassifier-17': RandomForestClassifier(min_samples_leaf=6),\n",
       "  'RandomForestClassifier-18': RandomForestClassifier(min_samples_leaf=6),\n",
       "  'RandomForestClassifier-19': RandomForestClassifier(min_samples_leaf=6),\n",
       "  'RandomForestClassifier-20': RandomForestClassifier(min_samples_leaf=6),\n",
       "  'RandomForestClassifier-21': RandomForestClassifier(min_samples_leaf=6),\n",
       "  'RandomForestClassifier-22': RandomForestClassifier(min_samples_leaf=6),\n",
       "  'RandomForestClassifier-23': RandomForestClassifier(min_samples_leaf=6),\n",
       "  'RandomForestClassifier-24': RandomForestClassifier(min_samples_leaf=6),\n",
       "  'RandomForestClassifier-25': RandomForestClassifier(min_samples_leaf=6)})"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t = X.iloc[:, [3, 12, 20, 23, 29, 31, 34, 40, 43, 53, 69, 70, 77, 80, 83, 92, 96]]\n",
    "x_scaled = scaling(x_t)\n",
    "#[x_PCA, pca] = training_with_PCA(x_t,PCA_num)\n",
    "runModelCV(rf, rf_params, x_scaled, y, 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB()\n",
    "nb_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kukkojoo/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:278: UserWarning: The total space of parameters 1 is smaller than n_iter=20. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runModelCV call done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(               Train Accuracy  Train Perplex  Validation Accuracy  \\\n",
       " GaussianNB-1         0.815217     279.109689             0.846995   \n",
       " GaussianNB-2         0.891304    1453.820546             0.825137   \n",
       " GaussianNB-3         0.913043   11426.027507             0.808743   \n",
       " GaussianNB-4         0.868132    1617.276681             0.825613   \n",
       " GaussianNB-5         0.846154    6172.482644             0.724796   \n",
       " GaussianNB-6         0.902174    6601.765442             0.819672   \n",
       " GaussianNB-7         0.826087     995.782342             0.838798   \n",
       " GaussianNB-8         0.858696     337.613283             0.833333   \n",
       " GaussianNB-9         0.835165     187.238424             0.828338   \n",
       " GaussianNB-10        0.879121    5088.878958             0.852861   \n",
       " GaussianNB-11        0.880435    3601.723612             0.816940   \n",
       " GaussianNB-12        0.880435    2047.100393             0.797814   \n",
       " GaussianNB-13        0.793478     211.268756             0.806011   \n",
       " GaussianNB-14        0.857143    1804.489820             0.820163   \n",
       " GaussianNB-15        0.824176     978.549600             0.833787   \n",
       " GaussianNB-16        0.815217     425.482859             0.806011   \n",
       " GaussianNB-17        0.923913   11411.411332             0.849727   \n",
       " GaussianNB-18        0.836957     930.824857             0.822404   \n",
       " GaussianNB-19        0.879121     494.289184             0.820163   \n",
       " GaussianNB-20        0.835165    1259.785505             0.828338   \n",
       " GaussianNB-21        0.815217     136.487154             0.833333   \n",
       " GaussianNB-22        0.891304    5153.900681             0.846995   \n",
       " GaussianNB-23        0.815217     397.948380             0.830601   \n",
       " GaussianNB-24        0.901099    1518.720661             0.850136   \n",
       " GaussianNB-25        0.890110    3735.150116             0.806540   \n",
       " \n",
       "                Validation Perplex Params  \n",
       " GaussianNB-1           304.092342     {}  \n",
       " GaussianNB-2           713.628826     {}  \n",
       " GaussianNB-3          3490.676488     {}  \n",
       " GaussianNB-4           389.087562     {}  \n",
       " GaussianNB-5          1275.200461     {}  \n",
       " GaussianNB-6           690.666467     {}  \n",
       " GaussianNB-7           469.805145     {}  \n",
       " GaussianNB-8           362.965551     {}  \n",
       " GaussianNB-9           184.340635     {}  \n",
       " GaussianNB-10         1369.394300     {}  \n",
       " GaussianNB-11         3955.505811     {}  \n",
       " GaussianNB-12         1098.772085     {}  \n",
       " GaussianNB-13          183.057174     {}  \n",
       " GaussianNB-14          476.943002     {}  \n",
       " GaussianNB-15          452.863945     {}  \n",
       " GaussianNB-16          362.351427     {}  \n",
       " GaussianNB-17         4174.891354     {}  \n",
       " GaussianNB-18          211.668244     {}  \n",
       " GaussianNB-19          493.076430     {}  \n",
       " GaussianNB-20          380.315537     {}  \n",
       " GaussianNB-21          162.941719     {}  \n",
       " GaussianNB-22         1619.540762     {}  \n",
       " GaussianNB-23          308.042184     {}  \n",
       " GaussianNB-24          658.126116     {}  \n",
       " GaussianNB-25         1770.861592     {}  ,\n",
       " {'GaussianNB-1': GaussianNB(),\n",
       "  'GaussianNB-2': GaussianNB(),\n",
       "  'GaussianNB-3': GaussianNB(),\n",
       "  'GaussianNB-4': GaussianNB(),\n",
       "  'GaussianNB-5': GaussianNB(),\n",
       "  'GaussianNB-6': GaussianNB(),\n",
       "  'GaussianNB-7': GaussianNB(),\n",
       "  'GaussianNB-8': GaussianNB(),\n",
       "  'GaussianNB-9': GaussianNB(),\n",
       "  'GaussianNB-10': GaussianNB(),\n",
       "  'GaussianNB-11': GaussianNB(),\n",
       "  'GaussianNB-12': GaussianNB(),\n",
       "  'GaussianNB-13': GaussianNB(),\n",
       "  'GaussianNB-14': GaussianNB(),\n",
       "  'GaussianNB-15': GaussianNB(),\n",
       "  'GaussianNB-16': GaussianNB(),\n",
       "  'GaussianNB-17': GaussianNB(),\n",
       "  'GaussianNB-18': GaussianNB(),\n",
       "  'GaussianNB-19': GaussianNB(),\n",
       "  'GaussianNB-20': GaussianNB(),\n",
       "  'GaussianNB-21': GaussianNB(),\n",
       "  'GaussianNB-22': GaussianNB(),\n",
       "  'GaussianNB-23': GaussianNB(),\n",
       "  'GaussianNB-24': GaussianNB(),\n",
       "  'GaussianNB-25': GaussianNB()})"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t = X.iloc[:, [0, 4, 10, 11, 12, 16, 18, 48, 49, 51, 53, 54, 55, 57, 58, 69, 70, 84, 86, 98, 99]]\n",
    "x_scaled = scaling(x_t)\n",
    "#[x_PCA, pca] = training_with_PCA(x_t,PCA_num)\n",
    "runModelCV(nb, nb_params, x_scaled, y, 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kukkojoo/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:278: UserWarning: The total space of parameters 1 is smaller than n_iter=20. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runModelCV call done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                         Train Accuracy  Train Perplex  Validation Accuracy  \\\n",
       " KNeighborsClassifier-1         0.858696   2.622265e+07             0.877049   \n",
       " KNeighborsClassifier-2         0.913043   1.036143e+09             0.866120   \n",
       " KNeighborsClassifier-3         0.923913   3.649031e+08             0.844262   \n",
       " KNeighborsClassifier-4         0.846154   1.064405e+07             0.850136   \n",
       " KNeighborsClassifier-5         0.890110   2.285999e+07             0.836512   \n",
       " KNeighborsClassifier-6         0.902174   1.972981e+07             0.868852   \n",
       " KNeighborsClassifier-7         0.891304   8.125180e+07             0.877049   \n",
       " KNeighborsClassifier-8         0.913043   6.262261e+09             0.849727   \n",
       " KNeighborsClassifier-9         0.890110   1.804012e+06             0.863760   \n",
       " KNeighborsClassifier-10        0.934066   1.836416e+09             0.841962   \n",
       " KNeighborsClassifier-11        0.869565   1.170974e+08             0.846995   \n",
       " KNeighborsClassifier-12        0.880435   1.179799e+08             0.863388   \n",
       " KNeighborsClassifier-13        0.836957   1.039006e+06             0.855191   \n",
       " KNeighborsClassifier-14        0.901099   1.111452e+10             0.858311   \n",
       " KNeighborsClassifier-15        0.879121   1.817753e+09             0.866485   \n",
       " KNeighborsClassifier-16        0.880435   5.620267e+07             0.844262   \n",
       " KNeighborsClassifier-17        0.923913   3.111255e+09             0.855191   \n",
       " KNeighborsClassifier-18        0.891304   2.327552e+08             0.833333   \n",
       " KNeighborsClassifier-19        0.890110   2.583885e+06             0.858311   \n",
       " KNeighborsClassifier-20        0.857143   2.564323e+06             0.855586   \n",
       " KNeighborsClassifier-21        0.880435   3.446317e+08             0.855191   \n",
       " KNeighborsClassifier-22        0.902174   9.457338e+06             0.866120   \n",
       " KNeighborsClassifier-23        0.913043   6.345940e+09             0.857923   \n",
       " KNeighborsClassifier-24        0.857143   1.544995e+07             0.825613   \n",
       " KNeighborsClassifier-25        0.923077   2.610407e+09             0.844687   \n",
       " \n",
       "                          Validation Perplex Params  \n",
       " KNeighborsClassifier-1         4.308490e+06     {}  \n",
       " KNeighborsClassifier-2         5.392309e+07     {}  \n",
       " KNeighborsClassifier-3         3.607067e+08     {}  \n",
       " KNeighborsClassifier-4         2.259694e+06     {}  \n",
       " KNeighborsClassifier-5         2.255085e+07     {}  \n",
       " KNeighborsClassifier-6         8.006559e+06     {}  \n",
       " KNeighborsClassifier-7         9.397484e+07     {}  \n",
       " KNeighborsClassifier-8         2.334662e+07     {}  \n",
       " KNeighborsClassifier-9         1.261568e+06     {}  \n",
       " KNeighborsClassifier-10        4.824743e+08     {}  \n",
       " KNeighborsClassifier-11        8.193136e+06     {}  \n",
       " KNeighborsClassifier-12        6.515381e+07     {}  \n",
       " KNeighborsClassifier-13        6.545849e+06     {}  \n",
       " KNeighborsClassifier-14        8.087455e+07     {}  \n",
       " KNeighborsClassifier-15        1.230258e+07     {}  \n",
       " KNeighborsClassifier-16        8.658819e+07     {}  \n",
       " KNeighborsClassifier-17        4.698859e+08     {}  \n",
       " KNeighborsClassifier-18        3.722400e+07     {}  \n",
       " KNeighborsClassifier-19        1.319597e+07     {}  \n",
       " KNeighborsClassifier-20        1.520237e+06     {}  \n",
       " KNeighborsClassifier-21        4.512825e+07     {}  \n",
       " KNeighborsClassifier-22        8.575968e+07     {}  \n",
       " KNeighborsClassifier-23        4.507164e+07     {}  \n",
       " KNeighborsClassifier-24        1.127180e+06     {}  \n",
       " KNeighborsClassifier-25        2.458166e+07     {}  ,\n",
       " {'KNeighborsClassifier-1': KNeighborsClassifier(),\n",
       "  'KNeighborsClassifier-2': KNeighborsClassifier(),\n",
       "  'KNeighborsClassifier-3': KNeighborsClassifier(),\n",
       "  'KNeighborsClassifier-4': KNeighborsClassifier(),\n",
       "  'KNeighborsClassifier-5': KNeighborsClassifier(),\n",
       "  'KNeighborsClassifier-6': KNeighborsClassifier(),\n",
       "  'KNeighborsClassifier-7': KNeighborsClassifier(),\n",
       "  'KNeighborsClassifier-8': KNeighborsClassifier(),\n",
       "  'KNeighborsClassifier-9': KNeighborsClassifier(),\n",
       "  'KNeighborsClassifier-10': KNeighborsClassifier(),\n",
       "  'KNeighborsClassifier-11': KNeighborsClassifier(),\n",
       "  'KNeighborsClassifier-12': KNeighborsClassifier(),\n",
       "  'KNeighborsClassifier-13': KNeighborsClassifier(),\n",
       "  'KNeighborsClassifier-14': KNeighborsClassifier(),\n",
       "  'KNeighborsClassifier-15': KNeighborsClassifier(),\n",
       "  'KNeighborsClassifier-16': KNeighborsClassifier(),\n",
       "  'KNeighborsClassifier-17': KNeighborsClassifier(),\n",
       "  'KNeighborsClassifier-18': KNeighborsClassifier(),\n",
       "  'KNeighborsClassifier-19': KNeighborsClassifier(),\n",
       "  'KNeighborsClassifier-20': KNeighborsClassifier(),\n",
       "  'KNeighborsClassifier-21': KNeighborsClassifier(),\n",
       "  'KNeighborsClassifier-22': KNeighborsClassifier(),\n",
       "  'KNeighborsClassifier-23': KNeighborsClassifier(),\n",
       "  'KNeighborsClassifier-24': KNeighborsClassifier(),\n",
       "  'KNeighborsClassifier-25': KNeighborsClassifier()})"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t = X.iloc[:, [16, 70, 71, 80, 82, 98]]\n",
    "x_scaled = scaling(x_t)\n",
    "#[x_PCA, pca] = training_with_PCA(x_t,PCA_num)\n",
    "runModelCV(knn, knn_params, x_scaled, y, 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
